# training
batch_size: 8
gradient_accumulation_steps: 4
total_round: 6
drop_out: 0.5
num_workers: 2
step1_epochs: 10
step2_epochs: 10
step3_epochs: 10
num_protos: 1
device: cuda
seed: 100
max_grad_norm: 10
task_length: 8
kl_temp: 2
temp: 0.1

# Encoder
bert_path: ./bert-base-uncased
max_length: 256
vocab_size: 30522
marker_size: 4
use_entity_marker: True
template: '[E1] [MASK] [E2]'
# pattern: entity_marker
pattern: prompt
encoder_output_size: 768

# dropout
drop_p: 0.1
f_pass: 10
kappa_neg: 0.03
kappa_pos: 0.05

# scheduler
T_mult: 1
rewarm_epoch_num: 2

# StepLR
decay_rate: 0.9
decay_steps: 800

# datapath
num_of_relation: 80
rel_index: data/fewrel/rel_index.npy
relation_file: data/fewrel/relation_name.txt
rel_cluster_label: data/fewrel/CFRLdata_10_100_10_10/rel_cluster_label_0.npy
training_file: data/fewrel/CFRLdata_10_100_10_10/train_0.txt
valid_file: data/fewrel/CFRLdata_10_100_10_10/valid_0.txt
test_file: data/fewrel/CFRLdata_10_100_10_10/test_0.txt


# newly added
retain_prev: False
use_marker: True